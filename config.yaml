# YAML files contain 'null', 'true', 'false';
# these need to be parsed to None, True, False -> use yaml.safe_load()
main:
  project_name: music_genre_classification # production name: music_genre_classification_prod; add tag prod
  experiment_name: dev
  execute_steps:
    # In production maybe we don't need all steps, so we can override execute_steps, e.g.:
    # mlflow run . -P hydra_options="main.execute_steps='train_random_forest'"
    # mlflow run . -P hydra_options="main.execute_steps='get_data,preprocess'"
    - get_data
    - preprocess
    - check_data
    - segregate
    - train_random_forest
    - evaluate
  # This seed will be used to seed the random number generator
  # to ensure repeatibility of the data splits and other
  # pseudo-random operations
  random_seed: 42
data:
  # We can use either a web link or a file path for files
  # but in the current implementation an URL passes to the requests module is required
  #file_url: "dataset/genres_mod.parquet"
  #file_url: "https://github.com/udacity/nd0821-c2-build-model-workflow-exercises/blob/master/lesson-2-data-exploration-and-preparation/exercises/exercise_4/starter/genres_mod.parquet?raw=true"
  file_url: "https://github.com/mxagar/music_genre_classification/blob/main/dataset/genres_mod.parquet?raw=true"
  reference_dataset: "music_genre_classification/preprocessed_data.csv:latest"
  # Threshold for Kolomorov-Smirnov test
  ks_alpha: 0.05
  test_size: 0.3
  val_size: 0.3
  # Stratify according to the target when splitting the data
  # in train/test or in train/val
  stratify: genre
random_forest_pipeline:
  # Recall we can perform hyperparameter tuning with hydra & mlflow
  # simply by overriding the parameters with sweeps via the CLI
  # or defining multiple values in the config.yaml
  random_forest:
    # This section is passed to the random forest model
    # as a dictionary of parameters, thus names must match with
    # the sklearn API.
    # Whenever we have model or other object with many parameters
    # we should write config files for them.
    # That is easier than passing parameters in the code or via CLI
    # and we can guarantee compatibility in the code in case the model API changes
    # (i.e., we would simply change the config file).
    n_estimators: 100
    criterion: 'gini'
    max_depth: 13
    min_samples_split: 2
    min_samples_leaf: 1
    min_weight_fraction_leaf: 0.0
    max_features: 'auto'
    max_leaf_nodes: null
    min_impurity_decrease: 0.0
    min_impurity_split: null
    bootstrap: true
    oob_score: false
    n_jobs: null
    # This is a different random seed than main.random_seed,
    # because this is used only within the RandomForest
    random_state: 42
    verbose: 0
    warm_start: false
    class_weight: "balanced"
    ccp_alpha: 0.0
    max_samples: null
  tfidf:
    max_features: 10
  features:
    numerical:
      - "danceability"
      - "energy"
      - "loudness"
      - "speechiness"
      - "acousticness"
      - "instrumentalness"
      - "liveness"
      - "valence"
      - "tempo"
      - "duration_ms"
    categorical:
      - "time_signature"
      - "key"
    nlp:
      - "text_feature"
  export_artifact: "model_export"
